{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "inverted_index = {\n",
    "    (b1, z1): [doc_id1, doc_id2, ...],\n",
    "    (b2, z2): [doc_id3, doc_id4, ...],\n",
    "    ...\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'constraint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconstraint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Problem\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrestore_tokens\u001b[39m(b_z_pairs, cardinality, k):\n\u001b[1;32m      4\u001b[0m     problem \u001b[38;5;241m=\u001b[39m Problem()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'constraint'"
     ]
    }
   ],
   "source": [
    "from constraint import Problem\n",
    "\n",
    "def restore_tokens(b_z_pairs, cardinality, k):\n",
    "    problem = Problem()\n",
    "    \n",
    "    # Variables: bits of the hash (excluding fixed bits)\n",
    "    for i, (b, z) in enumerate(b_z_pairs):\n",
    "        problem.addVariable(f\"hash_{i}\", generate_candidate_hashes(b, z, k))\n",
    "    \n",
    "    # Constraint: number of unique hashes must match cardinality\n",
    "    problem.addConstraint(lambda *hashes: len(set(hashes)) == cardinality, [f\"hash_{i}\" for i in range(len(b_z_pairs))])\n",
    "    \n",
    "    # Solve the problem\n",
    "    solutions = problem.getSolutions()\n",
    "    \n",
    "    # Return the restored tokens (hashes)\n",
    "    return solutions\n",
    "\n",
    "def generate_candidate_hashes(b, z, k):\n",
    "    # Generate all possible 64-bit hashes with first k bits = b and last z bits = 0\n",
    "    # This is a placeholder for the actual implementation\n",
    "    return [hash for hash in possible_hashes if (hash >> (64 - k)) == b and (hash & ((1 << z) - 1)) == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Incorporating token frequency across all documents can significantly improve the solution. Tokens with lower frequencies are more specific to certain documents and can act as strong discriminators during the token restoration process. By using token frequency as an additional criterion, we can prioritize rare tokens in the constraint model, making the solution more accurate and efficient.\n",
    "\n",
    "**Improved Solution**: Incorporating Token Frequency\n",
    "Key Idea:\n",
    "- Token Frequency: For each token hash, maintain its frequency across all documents (i.e., how many documents contain this token).\n",
    "\n",
    "- Relevance: Tokens with lower frequencies are more relevant to specific documents and can be used to narrow down the solution space in the constraint model.\n",
    "\n",
    "Updated Inverted Index Structure\n",
    "The inverted index will now store the frequency of each token hash in addition to the document references:\n",
    "\n",
    "inverted_index = {\n",
    "    (b1, z1): {\"frequency\": freq1, \"documents\": [doc_id1, doc_id2, ...]},\n",
    "    (b2, z2): {\"frequency\": freq2, \"documents\": [doc_id3, doc_id4, ...]},\n",
    "    ...\n",
    "}\n",
    "\n",
    "## Steps to Build the Inverted Index:\n",
    "1. Tokenization and Hashing: Tokenize each document and convert tokens into 64-bit hashes.\n",
    "\n",
    "2. Compression: Convert each hash into (b, z) as before.\n",
    "\n",
    "3. Update Inverted Index:\n",
    "\n",
    "    - For each (b, z) pair, update the frequency (increment by 1 for each document containing the token).\n",
    "\n",
    "    - Append the document ID to the list of documents for the (b, z) pair.\n",
    "\n",
    "## Constraint Model with Token Frequency\n",
    "### Key Changes:\n",
    "1. **Frequency-Based Prioritization:**\n",
    "\n",
    "    - Tokens with lower frequencies are more likely to be unique to the document and should be prioritized in the constraint model.\n",
    "\n",
    "    - Use frequency as a weight or cost function to guide the search for valid tokens.\n",
    "\n",
    "2. **Objective Function:**\n",
    "\n",
    "    - Minimize the total frequency of the selected tokens. This ensures that the solution favors rare tokens, which are more discriminative.\n",
    "\n",
    "3. **Constraints:**\n",
    "\n",
    "    - The number of unique tokens must match the document's cardinality.\n",
    "\n",
    "    - Each (b, z) pair must correspond to a valid token hash.\n",
    "\n",
    "## Algorithm Steps:\n",
    "1. Input:\n",
    "\n",
    "    - A list of (b, z) pairs associated with the document.\n",
    "\n",
    "    - The cardinality of the document (number of distinct tokens).\n",
    "\n",
    "    - Token frequencies from the inverted index.\n",
    "\n",
    "2. Generate Candidate Hashes:\n",
    "\n",
    "    - For each (b, z) pair, generate all possible 64-bit hashes that match the constraints (first k bits = b, last z bits = 0).\n",
    "\n",
    "3. Assign Frequencies:\n",
    "\n",
    "    - For each candidate hash, look up its frequency in the inverted index. If the hash is not in the index, assume a high frequency (e.g., infinity) to discourage its selection.\n",
    "\n",
    "4. Constraint Programming Model:\n",
    "\n",
    "    - Variables: The candidate hashes for each (b, z) pair.\n",
    "\n",
    "    - Constraints:\n",
    "\n",
    "       - The number of unique hashes must match the cardinality.\n",
    "\n",
    "    - Objective: Minimize the total frequency of the selected hashes.\n",
    "\n",
    "5. Solve the Model:\n",
    "\n",
    "    - Use a constraint solver to find the set of hashes that satisfies the constraints and minimizes the total frequency.\n",
    "\n",
    "## Example Code (Pseudocode):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constraint import Problem, MinConflictsSolver\n",
    "\n",
    "def restore_tokens_with_frequency(b_z_pairs, cardinality, k, inverted_index):\n",
    "    problem = Problem(MinConflictsSolver())\n",
    "    \n",
    "    # Generate candidate hashes for each (b, z) pair\n",
    "    candidates = []\n",
    "    for b, z in b_z_pairs:\n",
    "        hashes = generate_candidate_hashes(b, z, k)\n",
    "        candidates.append(hashes)\n",
    "    \n",
    "    # Add variables and their frequencies\n",
    "    for i, hashes in enumerate(candidates):\n",
    "        problem.addVariable(f\"hash_{i}\", hashes)\n",
    "    \n",
    "    # Constraint: number of unique hashes must match cardinality\n",
    "    problem.addConstraint(lambda *hashes: len(set(hashes)) == cardinality, [f\"hash_{i}\" for i in range(len(b_z_pairs))])\n",
    "    \n",
    "    # Objective: minimize total frequency of selected hashes\n",
    "    def frequency_cost(*hashes):\n",
    "        total_freq = 0\n",
    "        for hash_val in hashes:\n",
    "            # Look up frequency in inverted index\n",
    "            b_z = (hash_val >> (64 - k), count_trailing_zeros(hash_val))\n",
    "            if b_z in inverted_index:\n",
    "                total_freq += inverted_index[b_z][\"frequency\"]\n",
    "            else:\n",
    "                total_freq += float('inf')  # Penalize unknown hashes\n",
    "        return total_freq\n",
    "    \n",
    "    problem.addObjective(frequency_cost, [f\"hash_{i}\" for i in range(len(b_z_pairs))])\n",
    "    \n",
    "    # Solve the problem\n",
    "    solution = problem.getSolution()\n",
    "    \n",
    "    # Return the restored tokens (hashes)\n",
    "    return [solution[f\"hash_{i}\"] for i in range(len(b_z_pairs))]\n",
    "\n",
    "def generate_candidate_hashes(b, z, k):\n",
    "    # Generate all possible 64-bit hashes with first k bits = b and last z bits = 0\n",
    "    # This is a placeholder for the actual implementation\n",
    "    return [hash for hash in possible_hashes if (hash >> (64 - k)) == b and (hash & ((1 << z) - 1)) == 0]\n",
    "\n",
    "def count_trailing_zeros(hash_val):\n",
    "    # Count the number of trailing zeros in the hash\n",
    "    return (hash_val & -hash_val).bit_length() - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of Using Token Frequency:\n",
    "1. Improved Accuracy:\n",
    "\n",
    "    - Rare tokens are more likely to be unique to the document, reducing ambiguity in token restoration.\n",
    "\n",
    "2. Efficiency:\n",
    "\n",
    "    - The constraint model converges faster by prioritizing low-frequency tokens.\n",
    "\n",
    "3. Robustness:\n",
    "\n",
    "    - High-frequency tokens (e.g., stopwords) are less likely to be selected, reducing noise in the solution.\n",
    "\n",
    "Example Walkthrough:\n",
    "- Input:\n",
    "\n",
    "    - (b, z) pairs: [(b1, z1), (b2, z2), (b3, z3)]\n",
    "\n",
    "    - Cardinality: 3\n",
    "\n",
    "    - Inverted index with frequencies:\n",
    "\n",
    "        - (b1, z1): frequency = 2\n",
    "\n",
    "        - (b2, z2): frequency = 1\n",
    "\n",
    "        - (b3, z3): frequency = 5\n",
    "\n",
    "    - Candidate Hashes:\n",
    "\n",
    "        - For each (b, z), generate all possible hashes.\n",
    "\n",
    "    - Constraint Model:\n",
    "\n",
    "        - Select 3 unique hashes with the minimum total frequency.\n",
    "\n",
    "    - Solution:\n",
    "\n",
    "        - The model selects the hashes with frequencies 1, 2, and 5 (total = 8), favoring the lowest frequencies first.\n",
    "\n",
    "Conclusion:\n",
    "By incorporating token frequency into the constraint model, we can significantly improve the accuracy and efficiency of token restoration. This approach leverages the discriminative power of rare tokens, making it a robust solution for the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    some small correction to the provided solution.\n",
    "    (b, z) is one-to-many map. we can calculate frequency only for tokens and tokens with the same (b, z) can have different frequencies. we can use this fact to narrow scope of selected tokens that may lower dimentionality of the problem by picking only tokens with lower frequencies\n",
    "\n",
    "You're absolutely correct! The (b, z) representation is a one-to-many map, meaning multiple tokens (hashes) can share the same (b, z) pair but have different frequencies. By leveraging this fact, we can narrow the scope of candidate tokens by prioritizing those with lower frequencies. This reduces the dimensionality of the problem and improves the efficiency and accuracy of the constraint model.\n",
    "\n",
    "Updated Approach: Leveraging Token Frequencies within (b, z) Groups\n",
    "\n",
    "Key Idea:\n",
    "- For each (b, z) pair, there may be multiple tokens (hashes) with different frequencies.\n",
    "\n",
    "- Tokens with lower frequencies are more discriminative and should be prioritized in the constraint model.\n",
    "\n",
    "- Instead of considering all possible hashes for a (b, z) pair, we can pre-filter the candidate hashes to include only those with the lowest frequencies.\n",
    "\n",
    "Steps to Improve the Solution:\n",
    "\n",
    "1. Pre-Filter Candidate Hashes:\n",
    "\n",
    "    - For each (b, z) pair, retrieve all tokens (hashes) that map to it.\n",
    "\n",
    "    - Sort these tokens by frequency (ascending order).\n",
    "\n",
    "    - Select the top N tokens with the lowest frequencies for further consideration. This reduces the search space.\n",
    "\n",
    "2. Update Constraint Model:\n",
    "\n",
    "    - Use the pre-filtered candidate hashes in the constraint model.\n",
    "\n",
    "    - The objective remains to minimize the total frequency of the selected tokens.\n",
    "\n",
    "3. Cardinality Constraint:\n",
    "\n",
    "    - Ensure that the number of unique tokens selected matches the document's cardinality.\n",
    "\n",
    "Updated Algorithm:\n",
    "\n",
    "**Input:**\n",
    "\n",
    "- A list of (b, z) pairs associated with the document.\n",
    "\n",
    "- The cardinality of the document (number of distinct tokens).\n",
    "\n",
    "- A mapping from (b, z) to tokens (hashes) and their frequencies.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "- A set of tokens (hashes) that best match the document, given the constraints.\n",
    "\n",
    "**Pseudocode:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constraint import Problem, MinConflictsSolver\n",
    "\n",
    "def restore_tokens_with_frequency(b_z_pairs, cardinality, k, bz_to_tokens):\n",
    "    problem = Problem(MinConflictsSolver())\n",
    "    \n",
    "    # Pre-filter candidate hashes for each (b, z) pair\n",
    "    candidates = []\n",
    "    for b, z in b_z_pairs:\n",
    "        # Get all tokens for this (b, z) pair\n",
    "        tokens = bz_to_tokens.get((b, z), [])\n",
    "        # Sort tokens by frequency (ascending) and select top N\n",
    "        tokens_sorted = sorted(tokens, key=lambda x: x[\"frequency\"])[:10]  # Adjust N as needed\n",
    "        candidates.append([token[\"hash\"] for token in tokens_sorted])\n",
    "    \n",
    "    # Add variables to the problem\n",
    "    for i, hashes in enumerate(candidates):\n",
    "        problem.addVariable(f\"hash_{i}\", hashes)\n",
    "    \n",
    "    # Constraint: number of unique hashes must match cardinality\n",
    "    problem.addConstraint(lambda *hashes: len(set(hashes)) == cardinality, [f\"hash_{i}\" for i in range(len(b_z_pairs))])\n",
    "    \n",
    "    # Objective: minimize total frequency of selected hashes\n",
    "    def frequency_cost(*hashes):\n",
    "        total_freq = 0\n",
    "        for hash_val in hashes:\n",
    "            # Look up frequency in the pre-filtered candidates\n",
    "            for b, z in b_z_pairs:\n",
    "                tokens = bz_to_tokens.get((b, z), [])\n",
    "                for token in tokens:\n",
    "                    if token[\"hash\"] == hash_val:\n",
    "                        total_freq += token[\"frequency\"]\n",
    "                        break\n",
    "        return total_freq\n",
    "    \n",
    "    problem.addObjective(frequency_cost, [f\"hash_{i}\" for i in range(len(b_z_pairs))])\n",
    "    \n",
    "    # Solve the problem\n",
    "    solution = problem.getSolution()\n",
    "    \n",
    "    # Return the restored tokens (hashes)\n",
    "    return [solution[f\"hash_{i}\"] for i in range(len(b_z_pairs))]\n",
    "\n",
    "# Example data structure for bz_to_tokens\n",
    "bz_to_tokens = {\n",
    "    (b1, z1): [{\"hash\": hash1, \"frequency\": freq1}, {\"hash\": hash2, \"frequency\": freq2}, ...],\n",
    "    (b2, z2): [{\"hash\": hash3, \"frequency\": freq3}, {\"hash\": hash4, \"frequency\": freq4}, ...],\n",
    "    # ...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of Changes:\n",
    "1. **Pre-Filtering Candidates:**\n",
    "\n",
    "- For each (b, z) pair, we retrieve all tokens and sort them by frequency.\n",
    "\n",
    "- We select the top N tokens with the lowest frequencies (e.g., N = 10). This reduces the search space while preserving the most discriminative tokens.\n",
    "\n",
    "2. Frequency-Based Objective:\n",
    "\n",
    "- The objective function minimizes the total frequency of the selected tokens. This ensures that the solution favors rare tokens.\n",
    "\n",
    "3. Efficiency:\n",
    "\n",
    "- By pre-filtering candidates, the constraint model operates on a smaller set of variables, making it more efficient.\n",
    "\n",
    "Example Walkthrough:\n",
    "\n",
    "**Input:**\n",
    "- (b, z) pairs: [(b1, z1), (b2, z2), (b3, z3)]\n",
    "\n",
    "- Cardinality: 3\n",
    "\n",
    "- bz_to_tokens:\n",
    "\n",
    "    - (b1, z1): [{\"hash\": hash1, \"frequency\": 2}, {\"hash\": hash2, \"frequency\": 5}]\n",
    "\n",
    "    - (b2, z2): [{\"hash\": hash3, \"frequency\": 1}, {\"hash\": hash4, \"frequency\": 3}]\n",
    "\n",
    "    - (b3, z3): [{\"hash\": hash5, \"frequency\": 4}, {\"hash\": hash6, \"frequency\": 6}]\n",
    "\n",
    "**Pre-Filtering:**\n",
    "- For each (b, z), select the top N = 2 tokens with the lowest frequencies:\n",
    "\n",
    "    - (b1, z1): [hash1 (freq=2), hash2 (freq=5)]\n",
    "\n",
    "    - (b2, z2): [hash3 (freq=1), hash4 (freq=3)]\n",
    "\n",
    "    - (b3, z3): [hash5 (freq=4), hash6 (freq=6)]\n",
    "\n",
    "**Constraint Model:**\n",
    "- Select 3 unique hashes with the minimum total frequency.\n",
    "\n",
    "- Possible solution: [hash1 (freq=2), hash3 (freq=1), hash5 (freq=4)] (total frequency = 7).\n",
    "\n",
    "**Benefits of the Updated Solution:**\n",
    "1. Reduced Dimensionality:\n",
    "\n",
    "- By pre-filtering tokens, the search space is smaller, making the constraint model more efficient.\n",
    "\n",
    "2. Improved Accuracy:\n",
    "\n",
    "- Prioritizing low-frequency tokens ensures that the solution is more discriminative and relevant to the document.\n",
    "\n",
    "3. Scalability:\n",
    "\n",
    "- The approach scales better for large datasets, as the number of candidate tokens is controlled.\n",
    "\n",
    "This updated solution effectively leverages the one-to-many relationship between (b, z) and tokens, as well as token frequencies, to improve the token restoration process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
